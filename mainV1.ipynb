{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2209ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_solver.py\n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "\n",
    "class DataParser:\n",
    "    \"\"\"\n",
    "    Responsabilidade: Ler e analisar o arquivo de instância de forma otimizada.\n",
    "\n",
    "    Design: Esta classe pré-processa os dados para criar 'índices invertidos'\n",
    "    (item_to_orders, item_to_aisles). Isso acelera drasticamente a fase de \n",
    "    construção do modelo, que era nosso gargalo anterior.\n",
    "    \"\"\"\n",
    "    def __init__(self, filepath):\n",
    "        # O caminho para o arquivo de instância a ser lido.\n",
    "        self.filepath = filepath\n",
    "        \n",
    "        # Estrutura para guardar a qtde total de itens por pedido, útil para as restrições de tamanho.\n",
    "        self.orders_total_units = {}\n",
    "        \n",
    "        # Limites inferior e superior para o tamanho da wave.\n",
    "        self.lb = 0\n",
    "        self.ub = 0\n",
    "        \n",
    "        # --- ESTRUTURAS OTIMIZADAS (ÍNDICES INVERTIDOS) ---\n",
    "        # Usamos defaultdict para simplificar a adição de novos itens sem checagens extras.\n",
    "        # Mapeia um item para uma lista de pedidos que o contêm: {item_id: [(order_id, qty), ...]}\n",
    "        self.item_to_orders = defaultdict(list)\n",
    "        # Mapeia um item para uma lista de corredores que o contêm: {item_id: [(aisle_id, qty), ...]}\n",
    "        self.item_to_aisles = defaultdict(list)\n",
    "        \n",
    "        # Conjunto de todos os IDs de itens, pedidos e corredores para fácil iteração.\n",
    "        self.all_items = set()\n",
    "        self.all_orders = set()\n",
    "        self.all_aisles = set()\n",
    "\n",
    "\n",
    "    def parse(self):\n",
    "        \"\"\"\n",
    "        Executa a leitura e o pré-processamento do arquivo de entrada.\n",
    "        \"\"\"\n",
    "        print(f\"INFO: Iniciando a análise otimizada do arquivo: {self.filepath}\")\n",
    "        try:\n",
    "            with open(self.filepath, 'r') as f:\n",
    "                # Lê a primeira linha com as contagens gerais.\n",
    "                num_orders, _, num_aisles = map(int, f.readline().split())\n",
    "\n",
    "                # --- Processamento dos Pedidos ---\n",
    "                for i in range(num_orders):\n",
    "                    self.all_orders.add(i)\n",
    "                    line = list(map(int, f.readline().split()))\n",
    "                    total_units = 0\n",
    "                    # Itera sobre os pares de (item, quantidade) na linha.\n",
    "                    for j in range(line[0]):\n",
    "                        item_id = line[1 + 2*j]\n",
    "                        quantity = line[2 + 2*j]\n",
    "                        \n",
    "                        # AQUI: Populamos o índice invertido.\n",
    "                        self.item_to_orders[item_id].append((i, quantity))\n",
    "                        \n",
    "                        total_units += quantity\n",
    "                        self.all_items.add(item_id)\n",
    "                    self.orders_total_units[i] = total_units\n",
    "\n",
    "                # --- Processamento dos Corredores ---\n",
    "                for i in range(num_aisles):\n",
    "                    self.all_aisles.add(i)\n",
    "                    line = list(map(int, f.readline().split()))\n",
    "                    # Itera sobre os pares de (item, quantidade) na linha.\n",
    "                    for j in range(line[0]):\n",
    "                        item_id = line[1 + 2*j]\n",
    "                        quantity = line[2 + 2*j]\n",
    "                        \n",
    "                        # AQUI: Populamos o índice invertido dos corredores.\n",
    "                        self.item_to_aisles[item_id].append((i, quantity))\n",
    "                        self.all_items.add(item_id)\n",
    "\n",
    "                # Lê a última linha com os limites da wave.\n",
    "                self.lb, self.ub = map(int, f.readline().split())\n",
    "            \n",
    "            print(\"INFO: Análise do arquivo concluída com sucesso.\")\n",
    "            return True\n",
    "        except FileNotFoundError:\n",
    "            print(f\"ERRO: Arquivo de instância não encontrado em '{self.filepath}'\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"ERRO: Ocorreu um erro inesperado durante o parsing: {e}\")\n",
    "            return False\n",
    "\n",
    "\n",
    "class WaveOptimizer:\n",
    "    \"\"\"\n",
    "    Responsabilidade: Construir, resolver e extrair a solução do modelo de otimização.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, lambda_penalty=1.0, stagnation_node_limit=5000):\n",
    "        # O objeto 'data' vem do nosso DataParser.\n",
    "        self.data = data\n",
    "        self.model = gp.Model(\"Optimal_Wave_Selection\")\n",
    "        \n",
    "        # Parâmetros de controle da otimização.\n",
    "        self.lambda_penalty = lambda_penalty\n",
    "        self.stagnation_node_limit = stagnation_node_limit\n",
    "        \n",
    "        # Atributos para armazenar o estado do callback e a solução final.\n",
    "        self.stagnation_node_counter = 0\n",
    "        self.last_objective = -float('inf')\n",
    "        self.solution = {}\n",
    "\n",
    "    def _stagnation_callback(self, model, where):\n",
    "        \"\"\"\n",
    "        Callback para parar a otimização se não houver melhoria após um certo\n",
    "        número de nós explorados na árvore de Branch-and-Bound.\n",
    "        \"\"\"\n",
    "        # O callback é acionado a cada nó explorado pelo Gurobi.\n",
    "        if where == GRB.Callback.MIPNODE:\n",
    "            # Acessamos estatísticas do nó apenas se uma solução já foi encontrada.\n",
    "            if model.cbGet(GRB.Callback.MIPNODE_SOLCNT) > 0:\n",
    "                current_best_obj = model.cbGet(GRB.Callback.MIPNODE_OBJBST)\n",
    "                \n",
    "                # Se o melhor objetivo melhorou (com uma tolerância), zeramos a contagem.\n",
    "                if current_best_obj > self.last_objective + 1e-6:\n",
    "                    self.last_objective = current_best_obj\n",
    "                    self.stagnation_node_counter = 0\n",
    "                # Caso contrário, incrementamos.\n",
    "                else:\n",
    "                    self.stagnation_node_counter += 1\n",
    "                \n",
    "                # Se o limite de estagnação for atingido, terminamos a otimização.\n",
    "                if self.stagnation_node_counter >= self.stagnation_node_limit:\n",
    "                    print(f\"\\nINFO: Limite de estagnação ({self.stagnation_node_limit} nós) atingido. Terminando...\")\n",
    "                    model.terminate()\n",
    "\n",
    "    def build_and_solve(self):\n",
    "        \"\"\"\n",
    "        Orquestra a construção do modelo, a execução do solver e a extração da solução.\n",
    "        \"\"\"\n",
    "        print(\"INFO: Construindo o modelo de otimização...\")\n",
    "        \n",
    "        # --- Passo 1: Criar Variáveis de Decisão ---\n",
    "        # Para cada pedido/corredor, uma variável binária para decidir se será selecionado.\n",
    "        self.select_order = self.model.addVars(self.data.all_orders, vtype=GRB.BINARY, name=\"SelectOrder\")\n",
    "        self.visit_aisle = self.model.addVars(self.data.all_aisles, vtype=GRB.BINARY, name=\"VisitAisle\")\n",
    "\n",
    "        # --- Passo 2: Definir a Função Objetivo ---\n",
    "        # Maximizar: (Total de Itens) - lambda * (Total de Corredores)\n",
    "        total_items_in_wave = gp.quicksum(\n",
    "            self.data.orders_total_units[o] * self.select_order[o] for o in self.data.all_orders\n",
    "        )\n",
    "        total_aisles_visited = gp.quicksum(self.visit_aisle)\n",
    "        self.model.setObjective(\n",
    "            total_items_in_wave - self.lambda_penalty * total_aisles_visited, GRB.MAXIMIZE\n",
    "        )\n",
    "\n",
    "        # --- Passo 3: Adicionar Restrições ---\n",
    "        # Restrições de tamanho da wave (LB e UB)\n",
    "        self.model.addConstr(total_items_in_wave >= self.data.lb, \"Min_Wave_Size\")\n",
    "        self.model.addConstr(total_items_in_wave <= self.data.ub, \"Max_Wave_Size\")\n",
    "\n",
    "        # Restrições de estoque (usando a estrutura otimizada)\n",
    "        for item_id in self.data.all_items:\n",
    "            # Demanda total do item (soma apenas sobre pedidos relevantes)\n",
    "            total_demand = gp.quicksum(\n",
    "                quantity * self.select_order[order_id] \n",
    "                for order_id, quantity in self.data.item_to_orders.get(item_id, [])\n",
    "            )\n",
    "            # Estoque total do item (soma apenas sobre corredores relevantes)\n",
    "            total_stock = gp.quicksum(\n",
    "                quantity * self.visit_aisle[aisle_id] \n",
    "                for aisle_id, quantity in self.data.item_to_aisles.get(item_id, [])\n",
    "            )\n",
    "            # A demanda não pode exceder o estoque.\n",
    "            self.model.addConstr(total_demand <= total_stock, f\"Stock_Constraint_{item_id}\")\n",
    "\n",
    "        # --- Passo 4: Otimizar ---\n",
    "        print(\"INFO: Otimização iniciada...\")\n",
    "        self.model.optimize(self._stagnation_callback) # Otimiza usando o callback\n",
    "\n",
    "        # --- Passo 5: Extrair a Solução ---\n",
    "        if self.model.SolCount > 0:\n",
    "            print(f\"INFO: Solução final encontrada com valor objetivo = {self.model.ObjVal:.2f}\")\n",
    "            self.solution['selected_orders'] = [o for o, var in self.select_order.items() if var.X > 0.5]\n",
    "            self.solution['visited_aisles'] = [a for a, var in self.visit_aisle.items() if var.X > 0.5]\n",
    "        else:\n",
    "            print(\"ERRO: Nenhuma solução viável foi encontrada.\")\n",
    "\n",
    "def main(instance_file, output_file):\n",
    "    \"\"\"\n",
    "    Função principal que orquestra todo o processo de ponta a ponta.\n",
    "    \"\"\"\n",
    "    # Parâmetros que podem ser ajustados para experimentar com o modelo.\n",
    "    lambda_param = 2.0  # Penalidade por corredor.\n",
    "    stagnation_nodes = 200  # Nº de nós sem melhoria antes de parar.\n",
    "    time_limit_seconds = 400 # Limite de tempo total em segundos (10 min).\n",
    "\n",
    "    # --- 2. Parsing ---\n",
    "    parser = DataParser(instance_file)\n",
    "    if not parser.parse():\n",
    "        sys.exit(1) # Termina o script se o parsing falhar.\n",
    "\n",
    "    # --- 3. Otimização ---\n",
    "    optimizer = WaveOptimizer(\n",
    "        parser, \n",
    "        lambda_penalty=lambda_param, \n",
    "        stagnation_node_limit=stagnation_nodes\n",
    "    )\n",
    "    # Define um tempo limite geral para a otimização.\n",
    "    optimizer.model.setParam('TimeLimit', time_limit_seconds)\n",
    "    optimizer.build_and_solve()\n",
    "\n",
    "    # --- 4. Geração da Saída ---\n",
    "    if optimizer.solution:\n",
    "        print(f\"INFO: Escrevendo a solução para o arquivo: {output_file}\")\n",
    "        try:\n",
    "            with open(output_file, 'w') as f:\n",
    "                selected_orders = optimizer.solution['selected_orders']\n",
    "                visited_aisles = optimizer.solution['visited_aisles']\n",
    "                \n",
    "                f.write(f\"{len(selected_orders)}\\n\")\n",
    "                for order in sorted(selected_orders):\n",
    "                    f.write(f\"{order}\\n\")\n",
    "                \n",
    "                f.write(f\"{len(visited_aisles)}\\n\")\n",
    "                for aisle in sorted(visited_aisles):\n",
    "                    f.write(f\"{aisle}\\n\")\n",
    "            \n",
    "            print(\"INFO: Processo concluído com sucesso.\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERRO: Falha ao escrever o arquivo de saída: {e}\")\n",
    "    else:\n",
    "        print(\"AVISO: O processo terminou sem uma solução para escrever.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73044e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path_to_instances_b = './datasets/b'\n",
    "todas_instancias = os.listdir(path_to_instances_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a51c7b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(len(todas_instancias)):\\n    instance_file = f\\'{path_to_instances_b}/{todas_instancias[i]}\\'\\n    output_file = f\\'./{todas_instancias[i]}\\'\\n    #if __name__ == \"__main__\":\\n    main(instance_file, output_file)\\n\\n    run_checker(instance_file, output_file)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from checker_biblioteca.checker import run_checker\n",
    "'''\n",
    "for i in range(len(todas_instancias)):\n",
    "    instance_file = f'{path_to_instances_b}/{todas_instancias[i]}'\n",
    "    output_file = f'./{todas_instancias[i]}'\n",
    "    #if __name__ == \"__main__\":\n",
    "    main(instance_file, output_file)\n",
    "\n",
    "    run_checker(instance_file, output_file)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dcbb55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Iniciando a análise otimizada do arquivo: ./datasets/b/instance_0011.txt\n",
      "INFO: Análise do arquivo concluída com sucesso.\n",
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2638716\n",
      "Academic license - for non-commercial use only - expires 2026-03-19\n",
      "Set parameter TimeLimit to value 400\n",
      "INFO: Construindo o modelo de otimização...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Danone\\AppData\\Local\\Temp\\ipykernel_7852\\3811473819.py:151: DeprecationWarning: Calling quicksum on a tupledict is deprecated, use .sum() instead.\n",
      "  total_aisles_visited = gp.quicksum(self.visit_aisle)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Otimização iniciada...\n",
      "Gurobi Optimizer version 12.0.1 build v12.0.1rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-10510U CPU @ 1.80GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  400\n",
      "\n",
      "Optimize a model with 37822 rows, 45594 columns and 362018 nonzeros\n",
      "Model fingerprint: 0x0f72d410\n",
      "Variable types: 0 continuous, 45594 integer (45594 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+02]\n",
      "  Objective range  [1e+00, 3e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [9e+03, 2e+04]\n",
      "Found heuristic solution: objective 18157.000000\n",
      "Presolve removed 115 rows and 7194 columns\n",
      "Presolve time: 1.41s\n",
      "Presolved: 37707 rows, 38400 columns, 301458 nonzeros\n",
      "Found heuristic solution: objective 18142.000000\n",
      "Variable types: 0 continuous, 38400 integer (34353 binary)\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex\n",
      "Showing primal log only...\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   13332    1.8895771e+04   0.000000e+00   3.876486e+03      5s\n",
      "   28920    1.9000282e+04   0.000000e+00   4.687262e+02     10s\n",
      "   33013    1.9009336e+04   0.000000e+00   1.080428e+05     15s\n",
      "   37087    1.9020736e+04   0.000000e+00   6.396774e+02     20s\n",
      "   39776    1.9022915e+04   0.000000e+00   1.503843e+03     25s\n",
      "   42529    1.9024629e+04   0.000000e+00   6.402370e+02     30s\n",
      "   44964    1.9027239e+04   0.000000e+00   1.197635e+03     35s\n",
      "   47363    1.9029934e+04   0.000000e+00   3.047704e+01     40s\n",
      "   49865    1.9032973e+04   0.000000e+00   2.140108e+01     45s\n",
      "   52421    1.9035932e+04   0.000000e+00   5.362758e+02     50s\n",
      "   54891    1.9038598e+04   0.000000e+00   1.125073e+01     55s\n",
      "   57297    1.9041021e+04   0.000000e+00   1.007943e+03     60s\n",
      "   59524    1.9042825e+04   0.000000e+00   0.000000e+00     65s\n",
      "Concurrent spin time: 2.41s\n",
      "\n",
      "Solved with dual simplex\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   41672    1.9042825e+04   0.000000e+00   0.000000e+00     68s\n",
      "\n",
      "Use crossover to convert LP symmetric solution to basic solution...\n",
      "\n",
      "Root crossover log...\n",
      "\n",
      "    3599 DPushes remaining with DInf 0.0000000e+00                68s\n",
      "       0 DPushes remaining with DInf 0.0000000e+00                69s\n",
      "\n",
      "      20 PPushes remaining with PInf 0.0000000e+00                69s\n",
      "       0 PPushes remaining with PInf 0.0000000e+00                69s\n",
      "\n",
      "  Push phase complete: Pinf 0.0000000e+00, Dinf 1.1257965e-12     69s\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   45294    1.9042825e+04   0.000000e+00   0.000000e+00     69s\n",
      "   45294    1.9042825e+04   0.000000e+00   0.000000e+00     69s\n",
      "\n",
      "Root relaxation: objective 1.904282e+04, 45294 iterations, 67.85 seconds (77.00 work units)\n",
      "Total elapsed time = 70.10s (DegenMoves)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 19042.8247    0 19908 18157.0000 19042.8247  4.88%     -   70s\n",
      "H    0     0                    18785.000000 19042.8247  1.37%     -   70s\n",
      "H    0     0                    18787.000000 19042.8247  1.36%     -   71s\n",
      "H    0     0                    18851.000000 19042.8247  1.02%     -   71s\n",
      "H    0     0                    18907.000000 19042.8247  0.72%     -   84s\n",
      "     0     0 19041.6303    0 20967 18907.0000 19041.6303  0.71%     -  150s\n",
      "H    0     0                    18915.000000 19041.6302  0.67%     -  151s\n",
      "     0     0 19041.3582    0 21106 18915.0000 19041.3582  0.67%     -  186s\n",
      "     0     0 19041.3461    0 21184 18915.0000 19041.3461  0.67%     -  191s\n",
      "     0     0 19041.3439    0 21225 18915.0000 19041.3439  0.67%     -  193s\n",
      "     0     0 19041.2336    0 21478 18915.0000 19041.2336  0.67%     -  219s\n",
      "     0     0 19041.1865    0 21591 18915.0000 19041.1865  0.67%     -  227s\n",
      "     0     0 19041.1794    0 21336 18915.0000 19041.1794  0.67%     -  230s\n",
      "     0     0 19041.1781    0 21332 18915.0000 19041.1781  0.67%     -  231s\n",
      "     0     0 19041.1345    0 21155 18915.0000 19041.1345  0.67%     -  246s\n",
      "     0     0 19041.1251    0 21395 18915.0000 19041.1251  0.67%     -  250s\n",
      "     0     0 19041.1222    0 21307 18915.0000 19041.1222  0.67%     -  253s\n",
      "     0     0 19041.1099    0 21248 18915.0000 19041.1099  0.67%     -  264s\n",
      "     0     0 19041.1051    0 21447 18915.0000 19041.1051  0.67%     -  268s\n",
      "     0     0 19041.1037    0 21047 18915.0000 19041.1037  0.67%     -  269s\n",
      "H    0     0                    18943.000000 19041.1037  0.52%     -  277s\n",
      "     0     0 19041.0954    0 21129 18943.0000 19041.0954  0.52%     -  282s\n",
      "     0     0 19041.0954    0 21097 18943.0000 19041.0954  0.52%     -  284s\n",
      "H    0     0                    18945.000000 19041.0954  0.51%     -  309s\n",
      "H    0     0                    18957.000000 19041.0954  0.44%     -  309s\n",
      "     0     2 19041.0954    0 21092 18957.0000 19041.0954  0.44%     -  312s\n",
      "     1     4 19041.0597    1 21101 18957.0000 19041.0954  0.44%  2000  326s\n",
      "     3     8 19041.0391    2 21122 18957.0000 19041.0596  0.44%  2545  352s\n",
      "     7    12 19041.0134    3 21078 18957.0000 19041.0380  0.44%  2934  366s\n",
      "    11    18 19040.9592    4 21085 18957.0000 19041.0380  0.44%  2713  400s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 15\n",
      "  Cover: 898\n",
      "  Clique: 10\n",
      "  MIR: 792\n",
      "  StrongCG: 26\n",
      "  Zero half: 221\n",
      "  RLT: 553\n",
      "  Relax-and-lift: 425\n",
      "\n",
      "Explored 17 nodes (115736 simplex iterations) in 400.06 seconds (434.27 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 10: 18957 18945 18943 ... 18142\n",
      "\n",
      "Time limit reached\n",
      "Best objective 1.895700000000e+04, best bound 1.904100000000e+04, gap 0.4431%\n",
      "\n",
      "User-callback calls 45786, time in user-callback 0.36 sec\n",
      "INFO: Solução final encontrada com valor objetivo = 18957.00\n",
      "INFO: Escrevendo a solução para o arquivo: solution_0011.txt\n",
      "INFO: Processo concluído com sucesso.\n",
      "./datasets/b/instance_0011.txt Is solution feasible: True\n",
      "./datasets/b/instance_0011.txt Objective function value: 265.2916666666667\n"
     ]
    }
   ],
   "source": [
    "instance_file = './datasets/b/instance_0011.txt'\n",
    "output_file = 'solution_0011.txt'\n",
    "main(instance_file, output_file)\n",
    "run_checker(instance_file, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
